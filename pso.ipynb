{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pro",
      "provenance": [],
      "mount_file_id": "1GiWp1Cb72S_2fsQCdpUJDKT7omhAtKfj",
      "authorship_tag": "ABX9TyMHFbHeEnprn5M+uGqab2YA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sompote/COV_pile/blob/main/pso.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXp3bm18365m",
        "outputId": "1e3dd0cc-1dc1-42ce-d82d-449bef796a09"
      },
      "source": [
        "!pip install pyswarms"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyswarms\n",
            "  Downloading pyswarms-1.3.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▏                            | 10 kB 18.4 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 30 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 40 kB 18.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 51 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 61 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 71 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 81 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 92 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 102 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 104 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from pyswarms) (21.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pyswarms) (4.62.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from pyswarms) (3.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyswarms) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyswarms) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from pyswarms) (3.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyswarms) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.3.1->pyswarms) (1.15.0)\n",
            "Installing collected packages: pyswarms\n",
            "Successfully installed pyswarms-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSpoNc_bt2Cz"
      },
      "source": [
        "#PSO\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
        "from keras.layers import Activation, Dense,Flatten,LSTM,Dropout, GRU\n",
        "import warnings\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Flatten\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "\n",
        "df=pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Data/demo_pso.xlsx')\n",
        "\n",
        "#ks = pd.concat([df, df2,df3]).reset_index(drop=True)\n",
        "\n",
        "ks=pd.DataFrame()\n",
        "\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "-IK5pKETvouC",
        "outputId": "6df55968-5efe-4188-e32a-2b87b17a75ab"
      },
      "source": [
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>es</th>\n",
              "      <th>ev</th>\n",
              "      <th>q</th>\n",
              "      <th>p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.016667</td>\n",
              "      <td>10</td>\n",
              "      <td>3.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>20</td>\n",
              "      <td>6.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>30</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>40</td>\n",
              "      <td>13.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>50</td>\n",
              "      <td>16.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>60</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.116667</td>\n",
              "      <td>70</td>\n",
              "      <td>23.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>80</td>\n",
              "      <td>26.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>90</td>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>100</td>\n",
              "      <td>33.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.1</td>\n",
              "      <td>0.183333</td>\n",
              "      <td>110</td>\n",
              "      <td>36.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.2</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>120</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.3</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>130</td>\n",
              "      <td>43.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.4</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>140</td>\n",
              "      <td>46.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.5</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>150</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.6</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>160</td>\n",
              "      <td>53.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     es        ev   q           p\n",
              "0   0.1  0.016667   10   3.333333\n",
              "1   0.2  0.033333   20   6.666667\n",
              "2   0.3  0.050000   30  10.000000\n",
              "3   0.4  0.066667   40  13.333333\n",
              "4   0.5  0.083333   50  16.666667\n",
              "5   0.6  0.100000   60  20.000000\n",
              "6   0.7  0.116667   70  23.333333\n",
              "7   0.8  0.133333   80  26.666667\n",
              "8   0.9  0.150000   90  30.000000\n",
              "9   1.0  0.166667  100  33.333333\n",
              "10  1.1  0.183333  110  36.666667\n",
              "11  1.2  0.200000  120  40.000000\n",
              "12  1.3  0.216667  130  43.333333\n",
              "13  1.4  0.233333  140  46.666667\n",
              "14  1.5  0.250000  150  50.000000\n",
              "15  1.6  0.266667  160  53.333333"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "LjlRztPuv1Sp",
        "outputId": "17075962-e7d9-4ded-8fdb-0dface1f0f83"
      },
      "source": [
        "def scaler(xtrain1,y_train1):\n",
        "  #scaler\n",
        "  scaler_x = MinMaxScaler(feature_range=(-1,1))\n",
        "  scaler_y = MinMaxScaler(feature_range=(-1,1))\n",
        "  train_data_x = scaler_x.fit_transform(xtrain1)\n",
        "  train_data_y=scaler_y.fit_transform(y_train1)\n",
        "  return train_data_x, train_data_y, scaler_x, scaler_y\n",
        "\n",
        "#Build the DL model\n",
        "def model_fit(x_train,y_train):\n",
        "  model_test = Sequential()\n",
        "  model_test.add(Dense(50, activation=\"relu\",input_dim=x_train.shape[1]))\n",
        "  model_test.add(Dense(50))\n",
        "  model_test.add(Dense(50))\n",
        "  model_test.add(Dense(50))\n",
        "\n",
        "  model_test.add(Dense(y_train.shape[1]))\n",
        "  # Compile the model\n",
        "  model_test.compile(optimizer='Adam', loss='mean_squared_error',metrics=['mape'])\n",
        "  history = model_test.fit(x_train, y_train, batch_size=3, epochs=200, verbose=0)\n",
        "  #scores = model_dll.evaluate(x_test, y_test, verbose=0)\n",
        "  plt.plot(history.history['loss'])\n",
        "  return model_test\n",
        "\n",
        "def predict_value(model,scaler_x,scaler_y,input):\n",
        "#prediciton \n",
        "  input=[input]\n",
        "  input=np.reshape(input,(1,1))\n",
        "  input_scale=scaler_x.transform(input)\n",
        "  predict = model.predict([input_scale])\n",
        "  pre_nonscale=scaler_y.inverse_transform(predict)\n",
        "  return pre_nonscale\n",
        "\n",
        "ks=df\n",
        "yi=ks.drop(['es'], axis=1).to_numpy()\n",
        "  #yi=ks[['qn']].copy()\n",
        "xi=ks[['es']].copy().to_numpy()\n",
        "x_train, y_train, scaler_x, scaler_y =scaler(xi,yi)\n",
        "model_test=model_fit(x_train,y_train)\n",
        "predict_new=predict_value(model_test,scaler_x,scaler_y,0.2)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G49aLtTyKWeS",
        "outputId": "687ef843-5fac-46af-c304-8364b26552cf"
      },
      "source": [
        "predict"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.03163256, 20.286875  ,  7.30882   ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Zta0_oOv7NbO",
        "outputId": "a2bf63c2-53d1-4f91-fe88-6e47b746f59a"
      },
      "source": [
        "\n",
        "df2=pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Data/con_model.xlsx')\n",
        "\n",
        "#ks = pd.concat([df, df2,df3]).reset_index(drop=True)\n",
        "\n",
        "ks2=pd.DataFrame()\n",
        "def scaler(xtrain1,y_train1):\n",
        "  #scaler\n",
        "  scaler_x = MinMaxScaler(feature_range=(-1,1))\n",
        "  scaler_y = MinMaxScaler(feature_range=(-1,1))\n",
        "  train_data_x = scaler_x.fit_transform(xtrain1)\n",
        "  train_data_y=scaler_y.fit_transform(y_train1)\n",
        "  return train_data_x, train_data_y, scaler_x, scaler_y\n",
        "\n",
        "#Build the DL model\n",
        "def model_fit(x_train,y_train):\n",
        "  model_test = Sequential()\n",
        "  model_test.add(Dense(50, activation=\"relu\",input_dim=x_train.shape[1]))\n",
        "  model_test.add(Dense(50))\n",
        "  \n",
        "  model_test.add(Dense(y_train.shape[1]))\n",
        "  # Compile the model\n",
        "  model_test.compile(optimizer='Adam', loss='mean_squared_error',metrics=['mape'])\n",
        "  history = model_test.fit(x_train, y_train, batch_size=3, epochs=1000, verbose=0)\n",
        "  #scores = model_dll.evaluate(x_test, y_test, verbose=0)\n",
        "  plt.plot(history.history['loss'])\n",
        "  return model_test\n",
        "\n",
        "def predict_value_con(model,scaler_x,scaler_y,K,G,es):\n",
        "#prediciton \n",
        "  input=np.array([K,G,es])\n",
        "  input=np.reshape(input,(1,3))\n",
        "  input_scale=scaler_x.transform(input)\n",
        "  predict = model.predict([input_scale])\n",
        "  pre_nonscale=scaler_y.inverse_transform(predict)\n",
        "  return pre_nonscale\n",
        "\n",
        "ks=df2\n",
        "yi=ks.drop(['es','K','G'], axis=1).to_numpy()\n",
        "  #yi=ks[['qn']].copy()\n",
        "xi=ks[['K','G','es']].copy().to_numpy()\n",
        "x_train, y_train, scaler_xcon, scaler_ycon =scaler(xi,yi)\n",
        "model_con=model_fit(x_train,y_train)\n",
        "predict_ini=np.array([30000,20000,0.2])\n",
        "predict=predict_value_con(model_con,scaler_xcon,scaler_ycon,30000,20000,0.2)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P2DlIS91K_te",
        "outputId": "b3519648-5020-4a01-c310-bf356c95e994"
      },
      "source": [
        "df2"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>K</th>\n",
              "      <th>G</th>\n",
              "      <th>es</th>\n",
              "      <th>ev</th>\n",
              "      <th>q</th>\n",
              "      <th>p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>20.0</td>\n",
              "      <td>6.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>40.0</td>\n",
              "      <td>13.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>60.0</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>80.0</td>\n",
              "      <td>26.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>100.0</td>\n",
              "      <td>33.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>120.0</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.155556</td>\n",
              "      <td>140.0</td>\n",
              "      <td>46.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.177778</td>\n",
              "      <td>160.0</td>\n",
              "      <td>53.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>180.0</td>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>200.0</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.244444</td>\n",
              "      <td>220.0</td>\n",
              "      <td>73.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>240.0</td>\n",
              "      <td>80.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.288889</td>\n",
              "      <td>260.0</td>\n",
              "      <td>86.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>280.0</td>\n",
              "      <td>93.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>300.0</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>30000</td>\n",
              "      <td>20000</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.355556</td>\n",
              "      <td>320.0</td>\n",
              "      <td>106.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>66.0</td>\n",
              "      <td>22.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>126.0</td>\n",
              "      <td>42.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.240000</td>\n",
              "      <td>186.0</td>\n",
              "      <td>62.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1.640000</td>\n",
              "      <td>246.0</td>\n",
              "      <td>82.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>2.040000</td>\n",
              "      <td>306.0</td>\n",
              "      <td>102.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2.440000</td>\n",
              "      <td>366.0</td>\n",
              "      <td>122.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>7.1</td>\n",
              "      <td>2.840000</td>\n",
              "      <td>426.0</td>\n",
              "      <td>142.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>8.1</td>\n",
              "      <td>3.240000</td>\n",
              "      <td>486.0</td>\n",
              "      <td>162.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>9.1</td>\n",
              "      <td>3.640000</td>\n",
              "      <td>546.0</td>\n",
              "      <td>182.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>10.1</td>\n",
              "      <td>4.040000</td>\n",
              "      <td>606.0</td>\n",
              "      <td>202.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>11.1</td>\n",
              "      <td>4.440000</td>\n",
              "      <td>666.0</td>\n",
              "      <td>222.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>12.1</td>\n",
              "      <td>4.840000</td>\n",
              "      <td>726.0</td>\n",
              "      <td>242.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>13.1</td>\n",
              "      <td>5.240000</td>\n",
              "      <td>786.0</td>\n",
              "      <td>262.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>14.1</td>\n",
              "      <td>5.640000</td>\n",
              "      <td>846.0</td>\n",
              "      <td>282.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>5000</td>\n",
              "      <td>6000</td>\n",
              "      <td>15.1</td>\n",
              "      <td>6.040000</td>\n",
              "      <td>906.0</td>\n",
              "      <td>302.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>20.0</td>\n",
              "      <td>6.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>220.0</td>\n",
              "      <td>73.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>2.1</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>420.0</td>\n",
              "      <td>140.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>3.1</td>\n",
              "      <td>2.066667</td>\n",
              "      <td>620.0</td>\n",
              "      <td>206.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>4.1</td>\n",
              "      <td>2.733333</td>\n",
              "      <td>820.0</td>\n",
              "      <td>273.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>340.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>6.1</td>\n",
              "      <td>4.066667</td>\n",
              "      <td>1220.0</td>\n",
              "      <td>406.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>7.1</td>\n",
              "      <td>4.733333</td>\n",
              "      <td>1420.0</td>\n",
              "      <td>473.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>1620.0</td>\n",
              "      <td>540.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>9.1</td>\n",
              "      <td>6.066667</td>\n",
              "      <td>1820.0</td>\n",
              "      <td>606.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>10.1</td>\n",
              "      <td>6.733333</td>\n",
              "      <td>2020.0</td>\n",
              "      <td>673.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>11.1</td>\n",
              "      <td>7.400000</td>\n",
              "      <td>2220.0</td>\n",
              "      <td>740.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>12.1</td>\n",
              "      <td>8.066667</td>\n",
              "      <td>2420.0</td>\n",
              "      <td>806.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>13.1</td>\n",
              "      <td>8.733333</td>\n",
              "      <td>2620.0</td>\n",
              "      <td>873.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>14.1</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>2820.0</td>\n",
              "      <td>940.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>10000</td>\n",
              "      <td>20000</td>\n",
              "      <td>15.1</td>\n",
              "      <td>10.066667</td>\n",
              "      <td>3020.0</td>\n",
              "      <td>1006.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        K      G    es         ev       q            p\n",
              "0   30000  20000   0.1   0.022222    20.0     6.666667\n",
              "1   30000  20000   0.2   0.044444    40.0    13.333333\n",
              "2   30000  20000   0.3   0.066667    60.0    20.000000\n",
              "3   30000  20000   0.4   0.088889    80.0    26.666667\n",
              "4   30000  20000   0.5   0.111111   100.0    33.333333\n",
              "5   30000  20000   0.6   0.133333   120.0    40.000000\n",
              "6   30000  20000   0.7   0.155556   140.0    46.666667\n",
              "7   30000  20000   0.8   0.177778   160.0    53.333333\n",
              "8   30000  20000   0.9   0.200000   180.0    60.000000\n",
              "9   30000  20000   1.0   0.222222   200.0    66.666667\n",
              "10  30000  20000   1.1   0.244444   220.0    73.333333\n",
              "11  30000  20000   1.2   0.266667   240.0    80.000000\n",
              "12  30000  20000   1.3   0.288889   260.0    86.666667\n",
              "13  30000  20000   1.4   0.311111   280.0    93.333333\n",
              "14  30000  20000   1.5   0.333333   300.0   100.000000\n",
              "15  30000  20000   1.6   0.355556   320.0   106.666667\n",
              "16   5000   6000   0.1   0.040000     6.0     2.000000\n",
              "17   5000   6000   1.1   0.440000    66.0    22.000000\n",
              "18   5000   6000   2.1   0.840000   126.0    42.000000\n",
              "19   5000   6000   3.1   1.240000   186.0    62.000000\n",
              "20   5000   6000   4.1   1.640000   246.0    82.000000\n",
              "21   5000   6000   5.1   2.040000   306.0   102.000000\n",
              "22   5000   6000   6.1   2.440000   366.0   122.000000\n",
              "23   5000   6000   7.1   2.840000   426.0   142.000000\n",
              "24   5000   6000   8.1   3.240000   486.0   162.000000\n",
              "25   5000   6000   9.1   3.640000   546.0   182.000000\n",
              "26   5000   6000  10.1   4.040000   606.0   202.000000\n",
              "27   5000   6000  11.1   4.440000   666.0   222.000000\n",
              "28   5000   6000  12.1   4.840000   726.0   242.000000\n",
              "29   5000   6000  13.1   5.240000   786.0   262.000000\n",
              "30   5000   6000  14.1   5.640000   846.0   282.000000\n",
              "31   5000   6000  15.1   6.040000   906.0   302.000000\n",
              "32  10000  20000   0.1   0.066667    20.0     6.666667\n",
              "33  10000  20000   1.1   0.733333   220.0    73.333333\n",
              "34  10000  20000   2.1   1.400000   420.0   140.000000\n",
              "35  10000  20000   3.1   2.066667   620.0   206.666667\n",
              "36  10000  20000   4.1   2.733333   820.0   273.333333\n",
              "37  10000  20000   5.1   3.400000  1020.0   340.000000\n",
              "38  10000  20000   6.1   4.066667  1220.0   406.666667\n",
              "39  10000  20000   7.1   4.733333  1420.0   473.333333\n",
              "40  10000  20000   8.1   5.400000  1620.0   540.000000\n",
              "41  10000  20000   9.1   6.066667  1820.0   606.666667\n",
              "42  10000  20000  10.1   6.733333  2020.0   673.333333\n",
              "43  10000  20000  11.1   7.400000  2220.0   740.000000\n",
              "44  10000  20000  12.1   8.066667  2420.0   806.666667\n",
              "45  10000  20000  13.1   8.733333  2620.0   873.333333\n",
              "46  10000  20000  14.1   9.400000  2820.0   940.000000\n",
              "47  10000  20000  15.1  10.066667  3020.0  1006.666667"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onSISUuLwY1Y",
        "outputId": "7bdcf272-65c2-4a86-befa-f5367d11223d"
      },
      "source": [
        "predict_ini=np.array([30000,20000,0.2])\n",
        "predict=predict_value(model_con,scaler_x,scaler_y,predict_ini)\n",
        "predict"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.07126167, 39.835518  , 13.35872   ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m-85Ra8pw2P"
      },
      "source": [
        "#-----------------------------------------------------------------------------+\n",
        "#\n",
        "#   Nathan A. Rooy\n",
        "#   Simple Particle Swarm Optimization (PSO) with Python\n",
        "#   July, 2016\n",
        "#\n",
        "#------------------------------------------------------------------------------+\n",
        "\n",
        "#--- IMPORT DEPENDENCIES ------------------------------------------------------+\n",
        "\n",
        "from __future__ import division\n",
        "import random\n",
        "import math\n",
        "\n",
        "#--- COST FUNCTION ------------------------------------------------------------+\n",
        "\n",
        "# function we are attempting to optimize (minimize)\n",
        "def func1(x):\n",
        "    total=0\n",
        "    '''for i in range(len(x)):\n",
        "        total+=x[i]**2'''\n",
        "    total=predict_value_con(model_con,scaler_xcon,scaler_ycon,30000,20000,x[0])[0,0]\n",
        "\n",
        "    return total\n",
        "\n",
        "#--- MAIN ---------------------------------------------------------------------+\n",
        "\n",
        "class Particle:\n",
        "    def __init__(self,x0):\n",
        "        self.position_i=[]          # particle position\n",
        "        self.velocity_i=[]          # particle velocity\n",
        "        self.pos_best_i=[]          # best position individual\n",
        "        self.err_best_i=-1          # best error individual\n",
        "        self.err_i=-1               # error individual\n",
        "\n",
        "        for i in range(0,num_dimensions):\n",
        "            self.velocity_i.append(random.uniform(-1,1))\n",
        "            self.position_i.append(x0[i])\n",
        "\n",
        "    # evaluate current fitness\n",
        "    def evaluate(self,costFunc):\n",
        "        self.err_i=costFunc(self.position_i)\n",
        "\n",
        "        # check to see if the current position is an individual best\n",
        "        if self.err_i < self.err_best_i or self.err_best_i==-1:\n",
        "            self.pos_best_i=self.position_i\n",
        "            self.err_best_i=self.err_i\n",
        "\n",
        "    # update new particle velocity\n",
        "    def update_velocity(self,pos_best_g):\n",
        "        w=0.5       # constant inertia weight (how much to weigh the previous velocity)\n",
        "        c1=1        # cognative constant\n",
        "        c2=2        # social constant\n",
        "\n",
        "        for i in range(0,num_dimensions):\n",
        "            r1=random.random()\n",
        "            r2=random.random()\n",
        "\n",
        "            vel_cognitive=c1*r1*(self.pos_best_i[i]-self.position_i[i])\n",
        "            vel_social=c2*r2*(pos_best_g[i]-self.position_i[i])\n",
        "            self.velocity_i[i]=w*self.velocity_i[i]+vel_cognitive+vel_social\n",
        "\n",
        "    # update the particle position based off new velocity updates\n",
        "    def update_position(self,bounds):\n",
        "        for i in range(0,num_dimensions):\n",
        "            self.position_i[i]=self.position_i[i]+self.velocity_i[i]\n",
        "\n",
        "            # adjust maximum position if necessary\n",
        "            if self.position_i[i]>bounds[i][1]:\n",
        "                self.position_i[i]=bounds[i][1]\n",
        "\n",
        "            # adjust minimum position if neseccary\n",
        "            if self.position_i[i] < bounds[i][0]:\n",
        "                self.position_i[i]=bounds[i][0]\n",
        "                \n",
        "class PSO():\n",
        "    def __init__(self,costFunc,x0,bounds,num_particles,maxiter):\n",
        "        global num_dimensions\n",
        "\n",
        "        num_dimensions=len(x0)\n",
        "        err_best_g=-1                   # best error for group\n",
        "        pos_best_g=[]                   # best position for group\n",
        "\n",
        "        # establish the swarm\n",
        "        swarm=[]\n",
        "        for i in range(0,num_particles):\n",
        "            swarm.append(Particle(x0))\n",
        "\n",
        "        # begin optimization loop\n",
        "        i=0\n",
        "        while i < maxiter:\n",
        "            #print i,err_best_g\n",
        "            # cycle through particles in swarm and evaluate fitness\n",
        "            for j in range(0,num_particles):\n",
        "                swarm[j].evaluate(costFunc)\n",
        "\n",
        "                # determine if current particle is the best (globally)\n",
        "                if swarm[j].err_i < err_best_g or err_best_g == -1:\n",
        "                    pos_best_g=list(swarm[j].position_i)\n",
        "                    err_best_g=float(swarm[j].err_i)\n",
        "\n",
        "            # cycle through swarm and update velocities and position\n",
        "            for j in range(0,num_particles):\n",
        "                swarm[j].update_velocity(pos_best_g)\n",
        "                swarm[j].update_position(bounds)\n",
        "            i+=1\n",
        "\n",
        "        # print final results\n",
        "        print('FINAL:')\n",
        "        print('parameter:',pos_best_g)\n",
        "        print('error:',err_best_g)\n"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xykQO3Sm5cQh"
      },
      "source": [
        "def fc(x):\n",
        "  er=np.array([])\n",
        "  for es in np.arange(0.1,2,0.5):\n",
        "    predict_ini0=np.array([es],dtype=object)\n",
        "    predict_ini_1=np.array([x[0],x[1],es],dtype=object)\n",
        "    #fi=predict_value_con(model_con,scaler_xcon,scaler_ycon,x[0],x[1],es)[0,0]\n",
        "    fi=np.absolute(predict_value_con(model_con,scaler_xcon,scaler_ycon,x[0],x[1],es)[0,1]-predict_value(model_test,scaler_x,scaler_y,es)[0,1]) \n",
        "    er=np.append(er,fi) \n",
        "    f=np.average(er)                          \n",
        "    return f"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa3OgoqN81MH",
        "outputId": "844e75a7-afb3-425b-ec6e-4031de41d324"
      },
      "source": [
        "print('error:','err_best_g')"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: err_best_g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qZ7efp8xir5",
        "outputId": "5efe481d-f573-4cd0-8790-dcfb352ef227"
      },
      "source": [
        "initial=[10000,10000]               # initial starting location [x1,x2...]\n",
        "bounds=[(5000,80000),(5000,80000)]  # input bounds [(x1_min,x1_max),(x2_min,x2_max)...]\n",
        "\n",
        "\n",
        "PSO(fc,initial,bounds,num_particles=100,maxiter=30)"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL:\n",
            "[10000.128565794434, 5733.534357068894]\n",
            "0.08414173126220703\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.PSO at 0x7f2cf741ed10>"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vUlmst4b9fi2",
        "outputId": "43dd20db-79e4-450f-8eea-35f635e5e4a7"
      },
      "source": [
        "# import modules\n",
        "from pyswarms.single.global_best import GlobalBestPSO\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# create a parameterized version of the classic Rosenbrock unconstrained optimzation function\n",
        "'''def ftry(x):\n",
        "  f=predict_value(model_test,scaler_x,scaler_y,x[:,1])[-1,0]\n",
        "  return f'''\n",
        "def error(x):\n",
        "  er=np.array([])\n",
        "  for es in np.arange(0.1,2,0.5):\n",
        "    predict_ini0=np.array([es],dtype=object)\n",
        "    predict_ini_1=np.array([x[:,0],x[:,1],es],dtype=object)\n",
        "    K=x[:,1]\n",
        "    #fi=predict_value_con(model_con,scaler_xcon,scaler_ycon,K,340000,es)[0,0]\n",
        "    fi=np.absolute(predict_value_con(model_con,scaler_xcon,scaler_ycon,K,20000,es)[0,1]-predict_value(model_test,scaler_x,scaler_y,es)[0,1]) \n",
        "    er=np.append(er,fi) \n",
        "    f=np.average(er)                          \n",
        "    return f\n",
        "\n",
        "\n",
        "\n",
        "# instatiate the optimizer\n",
        "x_max = 70000 * np.ones(2)\n",
        "x_min = 1000 * x_max\n",
        "bounds = (x_min, x_max)\n",
        "options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
        "optimizer = GlobalBestPSO(n_particles=30, dimensions=2, options=options, bounds=bounds)\n",
        "\n",
        "# now run the optimization, pass a=1 and b=100 as a tuple assigned to args\n",
        "\n",
        "cost, pos = optimizer.optimize(error, 1000)\n",
        "\n",
        "#kwargs={\"a\": 1.0, \"b\": 100.0, 'c':0}\n",
        "#cost, pos = optimizer.optimize(error, 1000, **kwargs)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-02 18:44:21,491 - pyswarms.single.global_best - INFO - Optimize for 1000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
            "pyswarms.single.global_best:   0%|          |0/1000/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "pyswarms.single.global_best:   0%|          |0/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-179-bd8ccb58dbcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# now run the optimization, pass a=1 and b=100 as a tuple assigned to args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#kwargs={\"a\": 1.0, \"b\": 100.0, 'c':0}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyswarms/single/global_best.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, objective_func, iters, n_processes, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# Compute cost for current position and personal best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;31m# fmt: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_objective_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbest_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbest_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_pbest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;31m# Set best_cost_yet_found for ftol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyswarms/backend/operators.py\u001b[0m in \u001b[0;36mcompute_objective_function\u001b[0;34m(swarm, objective_func, pool, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \"\"\"\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         results = pool.map(\n",
            "\u001b[0;32m<ipython-input-179-bd8ccb58dbcb>\u001b[0m in \u001b[0;36merror\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#fi=predict_value_con(model_con,scaler_xcon,scaler_ycon,K,340000,es)[0,0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mfi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_value_con\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_con\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaler_xcon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaler_ycon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpredict_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaler_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaler_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-175-3b5e6af5f518>\u001b[0m in \u001b[0;36mpredict_value_con\u001b[0;34m(model, scaler_x, scaler_y, K, G, es)\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0minput_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m   \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_scale\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mpre_nonscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[0;32m--> 412\u001b[0;31m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl938hCtC6yb",
        "outputId": "c05a2207-5baf-44de-c503-98abdefabe00"
      },
      "source": [
        "es=0.5\n",
        "np.absolute(predict_value_con(model_con,scaler_xcon,scaler_ycon,predict_ini)[0,1]-\n",
        "              predict_value(model_test,scaler_x,scaler_y,es)[0,1]) "
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21.79002"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "-3Ex4cTDvdSL",
        "outputId": "95e5ec93-9d6d-4cd0-9d55-2db29adb8d8f"
      },
      "source": [
        "#Build the DL model\n",
        "def model_fit(x_train,y_train):\n",
        "  model_test = Sequential()\n",
        "  model_test.add(Dense(50, activation=\"relu\",input_dim=x_train.shape[1]))\n",
        "  model_test.add(Dense(50))\n",
        "  model_test.add(Dense(50))\n",
        "  model_test.add(Dense(50))\n",
        "\n",
        "  model_test.add(Dense(y_train.shape[1]))\n",
        "  # Compile the model\n",
        "  model_test.compile(optimizer='Adam', loss='mean_squared_error',metrics=['mape'])\n",
        "  history = model_test.fit(x_train, y_train, batch_size=3, epochs=200, verbose=0)\n",
        "  #scores = model_dll.evaluate(x_test, y_test, verbose=0)\n",
        "  plt.plot(history.history['loss'])\n",
        "  return model_test\n",
        "model_test=model_fit(x_train,y_train)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRIGcimKvdKv"
      },
      "source": [
        "def predict_value(model,scaler_x,scaler_y,input):\n",
        "  input=[input]\n",
        "  input=np.reshape(input,(1,1))\n",
        "  input_scale=scaler_x.transform(input)\n",
        "  predict = model.predict([input_scale])\n",
        "  pre_nonscale=scaler_y.inverse_transform(predict)\n",
        "  return pre_nonscale\n",
        "predict=predict_value(model_test,scaler_x,scaler_y,0.2)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVEdpi6lybE6",
        "outputId": "77963f47-d079-49b6-efd0-97a28dc5860a"
      },
      "source": [
        "predict"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.03369987, 20.008308  ,  6.6344886 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43P4rBmy02v7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}